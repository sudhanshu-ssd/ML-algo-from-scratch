{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77afe368-a367-452c-a13b-0fa6c6de8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ad74373-c302-4e16-9271-f36b41fd9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self,left_tree=None,right_tree=None,feature=None,threshold=None,value=None):\n",
    "        self.left_tree=left_tree\n",
    "        self.right_tree=right_tree\n",
    "        self.feature=feature\n",
    "        self.threshold=threshold\n",
    "        self.value=value\n",
    "\n",
    "    def is_leaf_node(self,node):\n",
    "        return node.value is not None\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40b32767-f32a-4a61-9af6-8caf8af11892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self,max_depth=100,min_samples=2):\n",
    "        self.max_depth=max_depth\n",
    "        self.min_samples=min_samples\n",
    "        self.root=None\n",
    "\n",
    "    def entropy(self,y):\n",
    "        labels,counts=np.unique(y,return_counts=True)\n",
    "        probs=counts/len(y)\n",
    "        return -np.sum(probs*np.log2(probs + 1e-15))\n",
    "\n",
    "    def info_gain(self,y,left_idx,right_idx):\n",
    "        root_ent=self.entropy(y)\n",
    "\n",
    "        left_child=y[left_idx]\n",
    "        right_child=y[right_idx]\n",
    "\n",
    "        left_weight=len(left_idx)/len(y)\n",
    "        right_weight=len(right_idx)/len(y)\n",
    "\n",
    "        left_ent=self.entropy(left_child)\n",
    "        right_ent=self.entropy(right_child)\n",
    "\n",
    "        return (root_ent - (left_ent*left_weight + right_ent*right_weight))\n",
    "\n",
    "    def best_split(self,X,y):\n",
    "        best_feature=None\n",
    "        gain=-1\n",
    "        best_threshold=None\n",
    "        best_left_idx=None\n",
    "        best_right_idx=None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds=np.unique(X[:,feature])\n",
    "\n",
    "            for t in thresholds:\n",
    "\n",
    "                left_idx=np.where(X[:,feature]<=t)[0]\n",
    "                right_idx=np.where(X[:,feature]>t)[0]\n",
    "\n",
    "                if len(left_idx)==0 or len(right_idx)==0:\n",
    "                    continue\n",
    "\n",
    "                gain=self.info_gain(y,left_idx,right_idx)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = t\n",
    "                    best_left_idx = left_idx\n",
    "                    best_right_idx = right_idx\n",
    "\n",
    "        return best_feature,best_threshold,best_left_idx,best_right_idx\n",
    "\n",
    "    def  most_common_label(self,y):\n",
    "        return counter(y).most_common(1)[0][0]\n",
    "        \n",
    "\n",
    "    def build_tree(self,X,y,depth=0):\n",
    "        nsamples,nfeatures=X.shape\n",
    "        labels=np.unique(y)\n",
    "\n",
    "        # stopping criteria\n",
    "\n",
    "        if (len(labels)==1 or depth>=self.max_depth or nsamples<self.min_samples):\n",
    "            leaf_value=self.most_common_label(y)\n",
    "            return node(value=leaf_value)\n",
    "\n",
    "        feature,threshold,left_idx,right_idx=self.best_split(X,y)\n",
    "\n",
    "        left_tree=self.build_tree(X[left_idx],y[left_idx],depth+1)\n",
    "        right_tree=self.build_tree(X[right_idx],y[right_idx],depth+1)\n",
    "        \n",
    "        return node(left_tree,right_tree,feature,threshold)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.root=self.build_tree(X,y)\n",
    "\n",
    "    def predict_sample(self,x,node):\n",
    "\n",
    "        if is_leaf_node(node):\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature]<=node.threshold:\n",
    "            return predict_sample(x,node.left_tree)\n",
    "        else:\n",
    "            return predict_sample(x,node.right_tree)\n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.array([self.predict_sample(X,self.root) for x in X])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66982230-4c9d-4a24-8cc6-5bb89b1ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandommForestClassifier:\n",
    "    def __init__(self,n_estimators=10,max_depth=100,min_samples=2,max_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.max_features = max_features  # if None, use sqrt(n_features) for classification\n",
    "        self.trees = []\n",
    "\n",
    "    def bootstrap_sample(self,X,y):\n",
    "        nsamples,nfeatures=X.shape\n",
    "        idx=np.random.choice(nsamples,size=nsamples,replace=True)\n",
    "        return X[idx],y[idx]\n",
    "\n",
    "    def feature_subset(self,X):\n",
    "        nsamples,nfeatures=X.shape\n",
    "        \n",
    "        if self.max_features is None:\n",
    "            feat=int(np.sqrt(nfeatures))\n",
    "        else:\n",
    "            feat=self.max_features\n",
    "        features_idx=np.random.choice(nfeatures,size=feat,replace=False)\n",
    "        return features_idx\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.trees=[]\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree=DecisionTreeClassifier(self.max_depth,self.min_samples)\n",
    "            \n",
    "            X_sample_size,y_sample_size=self.bootstrap_sample(X,y)\n",
    "            features_idx=self.feature_subset(X)\n",
    "            \n",
    "            tree.fit(X_sample_size[:,features_idx],y_sample_size)\n",
    "            self.trees.append((tree,features_idx))\n",
    "\n",
    "    def predict(self,X):\n",
    "        tree_preds=[]\n",
    "        for tree,features_idx in self.trees:\n",
    "            pred=tree.predict(X[:,features_idx])\n",
    "            tree_preds.append(pred)\n",
    "\n",
    "        tree_preds = np.array(tree_preds)  # shape = (n_trees, n_samples)\n",
    "        return np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=tree_preds)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd247a-0604-4873-b001-f0c3f188cbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
